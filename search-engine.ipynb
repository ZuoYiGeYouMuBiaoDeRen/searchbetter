{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import abc\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import gensim.models as models\n",
    "import gensim.models.word2vec as word2vec\n",
    "import secure\n",
    "\n",
    "import search\n",
    "reload(search)\n",
    "import rewriter\n",
    "reload(rewriter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = word2vec.Text8Corpus(secure.DATASET_PATH_BASE + 'enwik8')\n",
    "# self.model = word2vec.Word2Vec(corpus, workers=8)\n",
    "# self.model.save(self.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import *\n",
    "\n",
    "ph = Phrases(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phr = Phraser(ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'the', u'mayor', u'of', u'new', u'york', u'was', u'there']\n"
     ]
    }
   ],
   "source": [
    "print phr[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'chemical_reactions', u'are', u'cool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phr[[u'chemical',u'reactions',u'are',u'cool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "warnings.filterwarnings(\"ignore\", message=re.escape(\"For a faster implementation, use the gensim.models.phrases.Phraser class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = word2vec.Word2Vec(ph[corpus],size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'looking_forward', 0.9501240849494934),\n",
       " (u'compounds]', 0.9304075241088867),\n",
       " (u\"'''[[Internet\", 0.9185891151428223),\n",
       " (u'Marks]]', 0.9161316156387329),\n",
       " (u'(1995).', 0.9128404259681702),\n",
       " (u'anti-Communist', 0.9109591245651245),\n",
       " (u'Font', 0.9097691774368286),\n",
       " (u'[[National_Library', 0.9085487723350525),\n",
       " (u\"'''F'''\", 0.9075831174850464),\n",
       " (u'(Istat_2005)', 0.9073328971862793)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.most_similar(positive=['person'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-12be08144405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# made from https://github.com/facebookresearch/fastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/neel/Dropbox/Harvard/Classes/research/query-rewriter/fastText/fasttext'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_PATH_BASE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'wikiclean8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/neel/usr/anaconda2/lib/python2.7/site-packages/gensim/models/wrappers/fasttext.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, ft_path, corpus_file, output_file, model, size, alpha, window, min_count, loss, sample, negative, iter, min_n, max_n, sorted_vocab, threads)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_training_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neel/usr/anaconda2/lib/python2.7/site-packages/gensim/utils.pyc\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neel/usr/anaconda2/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_eintr_retry_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neel/usr/anaconda2/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_eintr_retry_call\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# WARNING: takes like 10 min to train\n",
    "# made from https://github.com/facebookresearch/fastText\n",
    "path = '/Users/neel/Dropbox/Harvard/Classes/research/query-rewriter/fastText/fasttext'\n",
    "fm = FastText.train(path, corpus_file=secure.DATASET_PATH_BASE + 'wikiclean8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Zork', 0.816493034362793),\n",
       " (u'Ankh-Morpork', 0.7960439920425415),\n",
       " (u'Artwork', 0.7774671316146851),\n",
       " (u'Network', 0.7542241811752319),\n",
       " (u'pork', 0.7466747760772705),\n",
       " (u'Clockwork', 0.7459302544593811),\n",
       " (u'homework', 0.7433512806892395),\n",
       " (u'Cork', 0.7420310974121094),\n",
       " (u'newsreel', 0.7417821884155273),\n",
       " (u'newline', 0.7417464256286621),\n",
       " (u'Pork', 0.7369546294212341),\n",
       " (u'(Network', 0.729056715965271),\n",
       " (u'company_slogan', 0.7259443998336792),\n",
       " (u'news]', 0.7191295623779297),\n",
       " (u'network', 0.7173770666122437),\n",
       " (u'new', 0.7120053172111511),\n",
       " (u'Yorkshire', 0.7098603248596191),\n",
       " (u'stonework', 0.7096399068832397),\n",
       " (u'new,', 0.7078135013580322),\n",
       " (u'artwork', 0.7072222232818604)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.similar_by_word('new_york', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "import secure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Zork', 0.816493034362793),\n",
       " (u'Ankh-Morpork', 0.7960439920425415),\n",
       " (u'Artwork', 0.7774671316146851),\n",
       " (u'Network', 0.7542241811752319),\n",
       " (u'pork', 0.7466747760772705),\n",
       " (u'Clockwork', 0.7459302544593811),\n",
       " (u'homework', 0.7433512806892395),\n",
       " (u'Cork', 0.7420310974121094),\n",
       " (u'newsreel', 0.7417821884155273),\n",
       " (u'newline', 0.7417464256286621),\n",
       " (u'Pork', 0.7369546294212341),\n",
       " (u'(Network', 0.729056715965271),\n",
       " (u'company_slogan', 0.7259443998336792),\n",
       " (u'news]', 0.7191295623779297),\n",
       " (u'network', 0.7173770666122437),\n",
       " (u'new', 0.7120053172111511),\n",
       " (u'Yorkshire', 0.7098603248596191),\n",
       " (u'stonework', 0.7096399068832397),\n",
       " (u'new,', 0.7078135013580322),\n",
       " (u'artwork', 0.7072222232818604)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.most_similar(positive=['new_york'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fm.save(secure.MODEL_PATH_BASE+'fasttext/fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fm2 = FastText.load(secure.MODEL_PATH_BASE+'fasttext/fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'biochemistry', 0.9830586910247803),\n",
       " (u'chemistry|', 0.9796395897865295),\n",
       " (u'(chemistry)', 0.9524341821670532),\n",
       " (u'chemistry,', 0.9513406753540039),\n",
       " (u'chemistry==', 0.9481360912322998),\n",
       " (u'biochemistry,', 0.9481123685836792),\n",
       " (u\"'Radiochemistry\", 0.9445796608924866),\n",
       " (u'Biochemistry', 0.9373379945755005),\n",
       " (u'Electrochemistry', 0.9102224111557007),\n",
       " (u\"chemistry'''\", 0.9014816284179688),\n",
       " (u'chemist', 0.8953343629837036),\n",
       " (u'chemistry.', 0.8936431407928467),\n",
       " (u'[[biochemistry|biochemical]]', 0.8890479803085327),\n",
       " (u'electrochemistry', 0.8872667551040649),\n",
       " (u'biochemistry.', 0.8862274289131165),\n",
       " (u'chemist,', 0.8851226568222046),\n",
       " (u'biochemist', 0.8840389251708984),\n",
       " (u'biochemist,', 0.8771650195121765),\n",
       " (u'[[chemistry|chemical]]', 0.8727388381958008),\n",
       " (u'Chemistry', 0.8726977109909058),\n",
       " (u'ischemic', 0.8639161586761475),\n",
       " (u'alchemist', 0.8624183535575867),\n",
       " (u'physiology', 0.8568892478942871),\n",
       " (u'Chemistry,', 0.8566870093345642),\n",
       " (u'[[electrochemistry|electrochemical]]', 0.8530532121658325)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm2.similar_by_word('chemistry', topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1962073 is out of bounds for size 1474803",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-982f31035151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/neel/usr/anaconda2/lib/python2.7/site-packages/gensim/models/wrappers/fasttext.pyc\u001b[0m in \u001b[0;36minit_ngrams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mngram_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mngram_hash\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1962073 is out of bounds for size 1474803"
     ]
    }
   ],
   "source": [
    "fm2.init_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = word2vec.LineSentence(secure.DATASET_PATH_BASE + 'wikiclean8')\n",
    "\n",
    "w2v = rewriter.Word2VecRewriter(corpus=None, create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'michigan',\n",
       " u'iowa',\n",
       " u'wisconsin',\n",
       " u'illinois',\n",
       " u'pennsylvania',\n",
       " u'birmingham',\n",
       " u'oregon',\n",
       " u'arizona',\n",
       " u'nebraska',\n",
       " u'kentucky',\n",
       " u'ohio']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.rewrite(\"ohio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import *\n",
    "\n",
    "phrases = Phrases(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "warnings.filterwarnings(\"ignore\", message=re.escape(\"For a faster implementation, use the gensim.models.phrases.Phraser class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_bigram = word2vec.Word2Vec(phrases[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'tyrannosaurus', 0.48952293395996094),\n",
       " (u'geared', 0.46873939037323),\n",
       " (u'rosencrantz', 0.40396764874458313),\n",
       " (u'bittorrent', 0.38522869348526),\n",
       " (u'concludes', 0.38276174664497375),\n",
       " (u'gur', 0.38172149658203125),\n",
       " (u'schaff_herzog', 0.38074791431427),\n",
       " (u'scotus', 0.3685116171836853),\n",
       " (u'fair_dealing', 0.36827796697616577),\n",
       " (u'be_remembered', 0.36687690019607544)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warning: you get a lot of gibberish! :(\n",
    "model_bigram.similar_by_word(\"new_york\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'teaching', 0.7068275213241577),\n",
       " (u'studying', 0.6510186791419983),\n",
       " (u'education', 0.6509798765182495),\n",
       " (u'communication', 0.6505078077316284),\n",
       " (u'skills', 0.6451709270477295),\n",
       " (u'expertise', 0.644391655921936),\n",
       " (u'knowledge', 0.6385884881019592),\n",
       " (u'curriculum', 0.6323326230049133),\n",
       " (u'creativity', 0.6304869055747986),\n",
       " (u'thinking', 0.6236695051193237)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word(\"learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phraser = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'this', u'is', u'a', u'chemical_reaction']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phraser[\"this is a chemical reaction\".split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "z = 0\n",
    "\n",
    "class PhraserCorpus(collections.Iterator):\n",
    "    \"\"\"\n",
    "    An iterable that wraps over a Corpus and the Phraser. When word2vec\n",
    "    requests a sentence from the corpus, this passes the sentence through the\n",
    "    Phraser first.\n",
    "    \n",
    "    This makes it very easy to implement bigrams with just a vanilla Corpus\n",
    "    and a simple Phraser.\n",
    "    \"\"\"\n",
    "    def __init__(self, phraser, corpus_iter):\n",
    "        self.corpus_iter = corpus_iter\n",
    "        self.phraser = phraser\n",
    "        \n",
    "    def __iter__(self): return self\n",
    "    \n",
    "    def next(self):\n",
    "        # wrap the corpus_iter.next() call with a call to the phraser \n",
    "        # if it throws a stop iteration\n",
    "        try:\n",
    "            sentence = self.corpus_iter.next()\n",
    "            global z\n",
    "            z += 1\n",
    "            # apply the phraser here \n",
    "            return phraser[sentence]\n",
    "        except StopIteration:\n",
    "            # we should stop when it stops\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci = iter(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc = PhraserCorpus(phraser, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod3 = word2vec.Word2Vec(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481196"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'diluted', 0.4184649884700775),\n",
       " (u'romantic_comedy', 0.37694448232650757),\n",
       " (u'shell', 0.3746798038482666),\n",
       " (u'bakunin', 0.37169894576072693),\n",
       " (u'dragonetti', 0.3654710352420807),\n",
       " (u'feasting', 0.3645687699317932),\n",
       " (u'candlemakers', 0.36218002438545227),\n",
       " (u'parish_churches', 0.3621782660484314),\n",
       " (u'innate_immunity', 0.35786914825439453),\n",
       " (u'suitable_for', 0.3556133210659027)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3.similar_by_word(\"french_revolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class ControlCorpus(collections.Iterator):\n",
    "    \"\"\"\n",
    "    An iterable that wraps over a Corpus and the Phraser. When word2vec\n",
    "    requests a sentence from the corpus, this passes the sentence through the\n",
    "    Phraser first.\n",
    "    \n",
    "    This makes it very easy to implement bigrams with just a vanilla Corpus\n",
    "    and a simple Phraser.\n",
    "    \"\"\"\n",
    "    def __init__(self, phraser, corpus_iter):\n",
    "        self.corpus_iter = corpus_iter\n",
    "        self.phraser = phraser\n",
    "        \n",
    "    def __iter__(self):\n",
    "        try:\n",
    "            while True:\n",
    "                yield self.corpus_iter.next()\n",
    "    \n",
    "#     def next(self):\n",
    "#         # wrap the corpus_iter.next() call with a call to the phraser \n",
    "#         # if it throws a stop iteration\n",
    "#         try:\n",
    "#             sentence = self.corpus_iter.next()\n",
    "#             global z\n",
    "#             z += 1\n",
    "#             # apply the phraser here \n",
    "#             return sentence\n",
    "#         except StopIteration:\n",
    "#             # we should stop when it stops\n",
    "#             raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci2 = iter(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd = ControlCorpus(phraser, ci2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod4 = word2vec.Word2Vec(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'bipartisan', 0.40629392862319946),\n",
       " (u'mes', 0.3698464632034302),\n",
       " (u'uprisings', 0.3670933246612549),\n",
       " (u'mats', 0.3569819927215576),\n",
       " (u'woman', 0.3505661189556122),\n",
       " (u'impressionists', 0.34208574891090393),\n",
       " (u'relatives', 0.32833635807037354),\n",
       " (u'specified', 0.32693660259246826),\n",
       " (u'expiry', 0.32566046714782715),\n",
       " (u'arts', 0.32548588514328003)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod4.similar_by_word(\"chemistry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'biochemistry', 0.8456375002861023),\n",
       " (u'biology', 0.8456199169158936),\n",
       " (u'physics', 0.8300018310546875),\n",
       " (u'mathematics', 0.7767337560653687),\n",
       " (u'molecular', 0.774981677532196),\n",
       " (u'optics', 0.7711237072944641),\n",
       " (u'synthesis', 0.7402553558349609),\n",
       " (u'genetics', 0.7353801727294922),\n",
       " (u'botany', 0.7348920106887817),\n",
       " (u'zoology', 0.7271405458450317)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.model.similar_by_word(\"chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.phrases.Phraser at 0x1eaf3c1d0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.LineSentence at 0x1eae84150>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ii = phraser[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1231eee90>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod5 = word2vec.Word2Vec(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'bipartisan', 0.40629392862319946),\n",
       " (u'strict_observance', 0.3852868974208832),\n",
       " (u'became_estranged', 0.37987571954727173),\n",
       " (u'juliet_barker', 0.3734053373336792),\n",
       " (u'team_finished', 0.37240421772003174),\n",
       " (u'motor_neuron', 0.3719816207885742),\n",
       " (u'thunder_bay', 0.3712693750858307),\n",
       " (u'mes', 0.3698464632034302),\n",
       " (u'contentious_issue', 0.3677879571914673),\n",
       " (u'uprisings', 0.3670933246612549)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod5.similar_by_word(\"chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a phraser doesn't work... sometimes\n",
    "\n",
    "Word2Vec has a feature called a Phraser, which generates a corpus of bigrams out of text. But oddly, sometimes it just doesn't work. For instance, here's a toy example. First, we use the raw corpus and a normal word2vec model, and everything works fine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = word2vec.LineSentence(secure.DATASET_PATH_BASE + 'test8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_model = word2vec.Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'from', 0.9997075796127319),\n",
       " (u'of', 0.9997063875198364),\n",
       " (u'this', 0.9997018575668335),\n",
       " (u'autism', 0.999697208404541),\n",
       " (u'anarchism', 0.9996892809867859),\n",
       " (u'in', 0.9996891617774963),\n",
       " (u'to', 0.9996873140335083),\n",
       " (u'and', 0.9996873140335083),\n",
       " (u'at', 0.9996867775917053),\n",
       " (u'an', 0.9996865391731262)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model.similar_by_word(\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we try using the Phraser class, we get total garbage (observe the drop from 99.97% relevance to 32%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phraser = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigrammed_model = word2vec.Word2Vec(phraser[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'example', 0.3241819441318512),\n",
       " (u'must', 0.2850297689437866),\n",
       " (u'now', 0.259639710187912),\n",
       " (u'point', 0.23865681886672974),\n",
       " (u'schools', 0.21188122034072876),\n",
       " (u'there_is', 0.2076726257801056),\n",
       " (u'true', 0.20666877925395966),\n",
       " (u'individual', 0.20091284811496735),\n",
       " (u'anarcha', 0.20034271478652954),\n",
       " (u'org', 0.1967254877090454)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrammed_model.similar_by_word(\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even stranger still - if we convert the  phraser into a list and then feed it into the model, the model walks OK and almost the same as before. But why???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_list = list(phraser[corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed_model = word2vec.Word2Vec(phrase_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'of', 0.9997658729553223),\n",
       " (u'from', 0.9997580647468567),\n",
       " (u'in', 0.9997528195381165),\n",
       " (u'autism', 0.999750018119812),\n",
       " (u'to', 0.9997495412826538),\n",
       " (u'and', 0.9997493028640747),\n",
       " (u'have', 0.9997491836547852),\n",
       " (u'this', 0.9997477531433105),\n",
       " (u'anarchism', 0.9997474551200867),\n",
       " (u'a', 0.9997439980506897)]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listed_model.similar_by_word(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
